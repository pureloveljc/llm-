#!/usr/bin/env python3
"""Batch‑transcribe videos in leaf directories **with word/segment timestamps**
   using whisper‑timestamped. Outputs a plain‑text file *and* an SRT subtitle file
   for each selected video.

   Usage examples
   -------------
   # 全部视频 → TXT+SRT
   python transcribe_leaf_videos_timestamped.py /data2/train_data \
       --model small --language zh --device cuda

   # 仅转写第 1‑3, 8, 20‑23 个视频
   python transcribe_leaf_videos_timestamped.py /data2/train_data \
       --select 1-3,8,20-23 --model medium --language zh --device cuda

   Requirements
   ------------
   pip install -U whisper-timestamped tqdm torch
   sudo apt-get install ffmpeg
"""

import argparse
import os
import sys
from datetime import timedelta
from pathlib import Path
from typing import List, Optional, Set

from whisper_timestamped import load_model, transcribe_timestamped
import torch
from tqdm import tqdm

# --------------------------------------------------------------------------------------
# Config
# --------------------------------------------------------------------------------------
VIDEO_EXTENSIONS: Set[str] = {
    ".mp4", ".m4v", ".mov", ".mkv", ".avi", ".flv", ".wmv", ".webm", ".mpg", ".mpeg", ".mpga", ".wav",
}

# --------------------------------------------------------------------------------------
# Helpers
# --------------------------------------------------------------------------------------

def find_leaf_video_files(root: Path) -> List[Path]:
    """Return *sorted* list of video files located in **leaf** directories (no sub‑dirs)."""
    leaf_videos: List[Path] = []
    for current, dirs, files in os.walk(root):
        if not dirs:  # leaf dir
            for fname in files:
                if Path(fname).suffix.lower() in VIDEO_EXTENSIONS:
                    leaf_videos.append(Path(current) / fname)
    return sorted(leaf_videos)


def parse_selection(sel: str, total: int) -> List[int]:
    """Parse a selection string into 0‑based indices.

    Supported formats
    -----------------
    - "all" / "*" / "" → select all
    - "1-10,15,20-23"   → multiple ranges / single points (1‑based)
    """
    sel = sel.strip().lower()
    if sel in {"all", "*", ""}:
        return list(range(total))

    indices: Set[int] = set()
    for part in sel.split(','):
        part = part.strip()
        if not part:
            continue
        if '-' in part:
            a, b = part.split('-', 1)
            try:
                start = int(a) - 1
                end = int(b) - 1
            except ValueError:
                raise ValueError(f"区间 '{part}' 不是有效数字")
            if start > end or start < 0:
                raise ValueError(f"无效区间 '{part}'")
            indices.update(range(start, end + 1))
        else:
            try:
                idx = int(part) - 1
            except ValueError:
                raise ValueError(f"索引 '{part}' 不是有效数字")
            indices.add(idx)
    return sorted(i for i in indices if 0 <= i < total)


def transcribe(file_path: Path, model, *, language: Optional[str] = None):
    """Transcribe a single video and return the *full result* dict (segments+words)."""
    return transcribe_timestamped(model, str(file_path), language=language)


def srt_timestamp(sec: float) -> str:
    """Convert seconds → 'HH:MM:SS,mmm' for SRT files.
    Handles both integer and fractional seconds safely."""
    total_ms = int(round(sec * 1000))
    hours = total_ms // 3_600_000
    minutes = (total_ms % 3_600_000) // 60_000
    seconds = (total_ms % 60_000) // 1000
    ms = total_ms % 1000
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{ms:03d}"

# --------------------------------------------------------------------------------------
# Main
# --------------------------------------------------------------------------------------

def main() -> None:
    parser = argparse.ArgumentParser(
        description="Transcribe videos in leaf directories with Whisper‑timestamped "
                    "(supports subset selection & outputs TXT + SRT).")
    parser.add_argument("root_dir", type=Path, help="根目录路径")

    parser.add_argument("--select", type=str, default="all",
                        help="选择要处理的视频编号，格式如 '1-10,15,20-23'，默认 all")
    parser.add_argument("--model", type=str, default="large",
                        help="Whisper 模型尺寸 (tiny | base | small | medium | large)")
    parser.add_argument("--device", type=str, default=None,
                        help="运算设备 (cuda | cpu)。默认自动检测。")
    parser.add_argument("--language", type=str, default=None,
                        help="语言提示，例如 zh, en …")
    parser.add_argument("--out-dir", type=Path, default=Path("/home/kede/2025/output_tts_初级会计"),
                        help="统一输出目录，不指定则写到视频所在目录")
    parser.add_argument("--overwrite", action="store_true",
                        help="若目标文件已存在则覆盖 (TXT & SRT)")

    args = parser.parse_args()

    # Load model
    device = args.device or ("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Loading Whisper‑timestamped model '{args.model}' on {device} …")
    model = load_model(args.model, device=device)

    # Find videos
    videos = find_leaf_video_files(args.root_dir)
    if not videos:
        print("未找到视频文件，结束。")
        return

    print("\n视频列表（共 %d 个）:" % len(videos))
    for i, vid in enumerate(videos, 1):
        print(f"[{i:>3}] {vid}")

    # Parse selection
    try:
        selected_indices = parse_selection(args.select, len(videos))
    except ValueError as e:
        print("选择参数错误:", e)
        sys.exit(1)

    if not selected_indices:
        print("没有任何视频被选中，结束。")
        return

    print("\n将处理 %d 个视频 → %s\n" % (len(selected_indices), args.select))

    for idx in tqdm(selected_indices, desc="Transcribing"):
        video = videos[idx]
        target_dir = args.out_dir or video.parent
        target_dir.mkdir(parents=True, exist_ok=True)

        txt_path = target_dir / (video.stem + ".txt")
        srt_path = target_dir / (video.stem + ".srt")

        if not args.overwrite and txt_path.exists() and srt_path.exists():
            tqdm.write(f"[SKIP] {video} 已存在 TXT & SRT。")
            continue

        try:
            result = transcribe(video, model, language=args.language)

            # Write plain text (concatenate segment texts)
            plain_text = "".join(seg["text"] for seg in result["segments"]).strip()
            txt_path.write_text(plain_text, encoding="utf-8")

            # Write SRT subtitle file
            with srt_path.open("w", encoding="utf-8") as f:
                for i, seg in enumerate(result["segments"], 1):
                    f.write(f"{i}\n")
                    f.write(f"{srt_timestamp(seg['start'])} --> {srt_timestamp(seg['end'])}\n")
                    f.write(seg["text"].strip() + "\n\n")

            tqdm.write(f"[OK] {video} → {txt_path.name}, {srt_path.name}")
        except Exception as exc:
            tqdm.write(f"[ERROR] {video}: {exc}")

# --------------------------------------------------------------------------------------
# Entry‑point
# --------------------------------------------------------------------------------------

if __name__ == "__main__":
    main()

# python /home/语音转化文字加时间戳.py  /data2/ 
